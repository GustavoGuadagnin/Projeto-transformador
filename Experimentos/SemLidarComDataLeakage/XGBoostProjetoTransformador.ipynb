{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavocoradin/Projeto-transformador/blob/main/XGBoostProjetoTransformador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_imports"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, make_scorer\n",
        "import time\n",
        "import psutil\n",
        "from memory_profiler import memory_usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_load_kaggle"
      },
      "outputs": [],
      "source": [
        "\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"usdot/flight-delays\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_load_data"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(path + \"/flights.csv\")\n",
        "print(f\"Dataset carregado com shape: {df.shape}\")\n",
        "print(f\"Colunas: {list(df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_data_cleaning"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Valores nulos por coluna (%):\")\n",
        "print(df.isna().sum() * 100 / len(df))\n",
        "delay_reason_cols = ['AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY']\n",
        "df[delay_reason_cols] = df[delay_reason_cols].fillna(0)\n",
        "\n",
        "\n",
        "df.drop(['CANCELLATION_REASON', 'FLIGHT_NUMBER', 'CANCELLED'], axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "df.drop('TAIL_NUMBER', axis=1, inplace=True)\n",
        "df.drop(['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'AIRLINE'], axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "df = df.dropna(subset=['DEPARTURE_TIME','DEPARTURE_DELAY','TAXI_OUT','WHEELS_OFF','SCHEDULED_TIME','ELAPSED_TIME','AIR_TIME','WHEELS_ON','TAXI_IN','ARRIVAL_TIME','ARRIVAL_DELAY'])\n",
        "\n",
        "print(f\"\\nShape ap√≥s limpeza: {df.shape}\")\n",
        "print(\"\\nValores nulos restantes (%):\")\n",
        "print(df.isna().sum() * 100 / len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_create_target"
      },
      "outputs": [],
      "source": [
        "df['DELAYED'] = df['ARRIVAL_DELAY'].apply(lambda x: 1 if x > 15 else 0)\n",
        "\n",
        "delay = df[df['DELAYED'] == 1]\n",
        "on_time = df[df['DELAYED'] == 0]\n",
        "\n",
        "delay_count = delay.shape[0]\n",
        "on_time_count = on_time.shape[0]\n",
        "total = delay_count + on_time_count\n",
        "delay_percentage = (delay_count / total) * 100\n",
        "on_time_percentage = (on_time_count / total) * 100\n",
        "\n",
        "print(f\"N√£o atrasados: {on_time_count:,}\".replace(\",\", \".\"))\n",
        "print(f\"Atrasados: {delay_count:,}\".replace(\",\", \".\"))\n",
        "print(f\"Percentual de voos n√£o atrasados: {on_time_percentage:.2f}%\")\n",
        "print(f\"Percentual de voos atrasados: {delay_percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_undersampling"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "X = df.drop(columns=['DELAYED'])\n",
        "y = df['DELAYED']\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "df_undersampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "on_time_count = (df_undersampled['DELAYED'] == 0).sum()\n",
        "delay_count = (df_undersampled['DELAYED'] == 1).sum()\n",
        "total = on_time_count + delay_count\n",
        "on_time_percentage = (on_time_count / total) * 100\n",
        "delay_percentage = (delay_count / total) * 100\n",
        "\n",
        "print(f\"\\nAp√≥s undersampling:\")\n",
        "print(f\"N√£o atrasados: {on_time_count:,}\".replace(\",\", \".\"))\n",
        "print(f\"Atrasados: {delay_count:,}\".replace(\",\", \".\"))\n",
        "print(f\"Percentual de voos n√£o atrasados: {on_time_percentage:.2f}%\")\n",
        "print(f\"Percentual de voos atrasados: {delay_percentage:.2f}%\")\n",
        "print(f\"Shape do dataset balanceado: {df_undersampled.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_sample_data"
      },
      "outputs": [],
      "source": [
        "df_delayed = df_undersampled[df_undersampled['DELAYED'] == 1]\n",
        "df_on_time = df_undersampled[df_undersampled['DELAYED'] == 0]\n",
        "\n",
        "sample_size_per_class = 1000000\n",
        "\n",
        "df_delayed_sample = df_delayed.sample(n=sample_size_per_class, random_state=42)\n",
        "df_on_time_sample = df_on_time.sample(n=sample_size_per_class, random_state=42)\n",
        "\n",
        "df_sample = pd.concat([df_delayed_sample, df_on_time_sample])\n",
        "\n",
        "df_sample = df_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(\"Shape do DataFrame original:\", df_undersampled.shape)\n",
        "print(\"Shape do DataFrame amostrado:\", df_sample.shape)\n",
        "print(\"\\nDistribui√ß√£o da classe 'DELAYED' no DataFrame amostrado:\")\n",
        "print(df_sample['DELAYED'].value_counts())\n",
        "print(f\"\\n‚úÖ XGBoost pode processar {sample_size_per_class*2:,} amostras com excelente escalabilidade\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_split_data"
      },
      "outputs": [],
      "source": [
        "X_sample = df_sample.drop(columns=['DELAYED'])\n",
        "y_sample = df_sample['DELAYED']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sample, y_sample,\n",
        "    test_size=0.3,\n",
        "    stratify=y_sample,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Tamanho do conjunto de treino: {X_train.shape[0]}\")\n",
        "print(f\"Tamanho do conjunto de teste: {X_test.shape[0]}\")\n",
        "print(f\"Distribui√ß√£o no treino: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"Distribui√ß√£o no teste: {y_test.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_train"
      },
      "outputs": [],
      "source": [
        "neg_count = (y_train == 0).sum()\n",
        "pos_count = (y_train == 1).sum()\n",
        "scale_pos_weight = neg_count / pos_count\n",
        "\n",
        "print(f\"Calculando scale_pos_weight: {neg_count} / {pos_count} = {scale_pos_weight:.4f}\")\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,      \n",
        "    max_depth=6,               \n",
        "    learning_rate=0.1,        \n",
        "    scale_pos_weight=scale_pos_weight, \n",
        "    random_state=42,\n",
        "    n_jobs=-1,                 \n",
        "    eval_metric='logloss'     \n",
        ")\n",
        "\n",
        "start_time_train = time.time()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "end_time_train = time.time()\n",
        "\n",
        "training_time = end_time_train - start_time_train\n",
        "print(f\"\\nTempo de Treinamento: {training_time:.4f} segundos\")\n",
        "print(f\"Modelo XGBoost treinado com {xgb_model.n_estimators} √°rvores\")\n",
        "print(f\"Profundidade m√°xima: {xgb_model.max_depth}\")\n",
        "print(f\"Taxa de aprendizado: {xgb_model.learning_rate}\")\n",
        "print(f\"Scale pos weight: {xgb_model.scale_pos_weight:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_predict"
      },
      "outputs": [],
      "source": [
        "start_time_pred = time.time()\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "end_time_pred = time.time()\n",
        "\n",
        "prediction_time = end_time_pred - start_time_pred\n",
        "print(f\"Tempo de Predi√ß√£o: {prediction_time:.4f} segundos\")\n",
        "print(f\"Predi√ß√µes realizadas para {len(X_test)} amostras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_metrics"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "tpr = recall\n",
        "tnr = tn / (tn + fp)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"=== M√âTRICAS NO CONJUNTO DE TESTE ===\")\n",
        "print(f\"Acur√°cia: {accuracy:.4f}\")\n",
        "print(f\"Precis√£o: {precision:.4f}\")\n",
        "print(f\"Recall (TPR): {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "print(f\"True Negative Rate (TNR): {tnr:.4f}\")\n",
        "print(\"\\nMatriz de Confus√£o:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_train_metrics"
      },
      "outputs": [],
      "source": [
        "y_train_pred = xgb_model.predict(X_train)\n",
        "\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "precision_train = precision_score(y_train, y_train_pred)\n",
        "recall_train = recall_score(y_train, y_train_pred)\n",
        "f1_train = f1_score(y_train, y_train_pred)\n",
        "tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
        "tpr_train = recall_train\n",
        "tnr_train = tn / (tn + fp)\n",
        "\n",
        "print(\"=== M√âTRICAS NO CONJUNTO DE TREINO ===\")\n",
        "print(f\"Acur√°cia: {accuracy_train:.4f}\")\n",
        "print(f\"Precis√£o: {precision_train:.4f}\")\n",
        "print(f\"Recall (TPR): {recall_train:.4f}\")\n",
        "print(f\"F1-score: {f1_train:.4f}\")\n",
        "print(f\"True Negative Rate (TNR): {tnr_train:.4f}\")\n",
        "\n",
        "print(\"\\n=== COMPARA√á√ÉO TREINO vs TESTE ===\")\n",
        "print(f\"Diferen√ßa de Acur√°cia: {accuracy_train - accuracy:.4f}\")\n",
        "print(f\"Diferen√ßa de F1-score: {f1_train - f1:.4f}\")\n",
        "\n",
        "acc_diff = accuracy_train - accuracy\n",
        "if acc_diff > 0.05:\n",
        "    print(f\"\\n‚ö†Ô∏è  POSS√çVEL OVERFITTING DETECTADO!\")\n",
        "    print(f\"Diferen√ßa de acur√°cia treino-teste: {acc_diff:.4f}\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Modelo parece estar generalizando bem.\")\n",
        "    print(f\"Diferen√ßa de acur√°cia treino-teste: {acc_diff:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_cv"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"VALIDA√á√ÉO CRUZADA 5-FOLDS - XGBOOST\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'f1': make_scorer(f1_score)\n",
        "}\n",
        "\n",
        "xgb_cv = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "cv_results = cross_validate(xgb_cv, X_sample, y_sample, cv=cv, scoring=scoring, return_train_score=True)\n",
        "\n",
        "print(f\"Acur√°cia - Treino: {cv_results['train_accuracy'].mean():.4f} ¬± {cv_results['train_accuracy'].std():.4f}\")\n",
        "print(f\"Acur√°cia - Valida√ß√£o: {cv_results['test_accuracy'].mean():.4f} ¬± {cv_results['test_accuracy'].std():.4f}\")\n",
        "print(f\"Precis√£o - Treino: {cv_results['train_precision'].mean():.4f} ¬± {cv_results['train_precision'].std():.4f}\")\n",
        "print(f\"Precis√£o - Valida√ß√£o: {cv_results['test_precision'].mean():.4f} ¬± {cv_results['test_precision'].std():.4f}\")\n",
        "print(f\"Recall - Treino: {cv_results['train_recall'].mean():.4f} ¬± {cv_results['train_recall'].std():.4f}\")\n",
        "print(f\"Recall - Valida√ß√£o: {cv_results['test_recall'].mean():.4f} ¬± {cv_results['test_recall'].std():.4f}\")\n",
        "print(f\"F1-score - Treino: {cv_results['train_f1'].mean():.4f} ¬± {cv_results['train_f1'].std():.4f}\")\n",
        "print(f\"F1-score - Valida√ß√£o: {cv_results['test_f1'].mean():.4f} ¬± {cv_results['test_f1'].std():.4f}\")\n",
        "\n",
        "cv_acc_diff = cv_results['train_accuracy'].mean() - cv_results['test_accuracy'].mean()\n",
        "if cv_acc_diff > 0.05:\n",
        "    print(f\"\\n‚ö†Ô∏è  POSS√çVEL OVERFITTING DETECTADO NA VALIDA√á√ÉO CRUZADA!\")\n",
        "    print(f\"Diferen√ßa de acur√°cia treino-valida√ß√£o: {cv_acc_diff:.4f}\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Modelo generalizando bem na valida√ß√£o cruzada.\")\n",
        "    print(f\"Diferen√ßa de acur√°cia treino-valida√ß√£o: {cv_acc_diff:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_performance"
      },
      "outputs": [],
      "source": [
        "process = psutil.Process()\n",
        "\n",
        "xgb_perf = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "def train_xgb_model():\n",
        "    xgb_perf.fit(X_train, y_train)\n",
        "start_time_train = time.time()\n",
        "mem_usage_train = memory_usage(train_xgb_model)\n",
        "end_time_train = time.time()\n",
        "training_time = end_time_train - start_time_train\n",
        "train_ips = len(X_train) / training_time\n",
        "\n",
        "def predict_xgb_model():\n",
        "    global y_pred_perf\n",
        "    y_pred_perf = xgb_perf.predict(X_test)\n",
        "\n",
        "cpu_percent_before = process.cpu_percent(interval=None)\n",
        "start_time_pred = time.time()\n",
        "mem_usage_pred = memory_usage(predict_xgb_model)\n",
        "end_time_pred = time.time()\n",
        "cpu_percent_after = process.cpu_percent(interval=None)\n",
        "\n",
        "prediction_time = end_time_pred - start_time_pred\n",
        "pred_ips = len(X_test) / prediction_time\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"AN√ÅLISE DE DESEMPENHO COMPUTACIONAL - XGBOOST\")\n",
        "print(\"=\"*50)\n",
        "print(f\"üïí Tempo de Treinamento: {training_time:.4f} s\")\n",
        "print(f\"üïí Tempo de Predi√ß√£o: {prediction_time:.4f} s\")\n",
        "print(f\"üìà Mem√≥ria (Treinamento): {max(mem_usage_train):.2f} MB\")\n",
        "print(f\"üìà Mem√≥ria (Predi√ß√£o): {max(mem_usage_pred):.2f} MB\")\n",
        "print(f\"‚öôÔ∏è CPU usada na predi√ß√£o: {cpu_percent_after:.2f}%\")\n",
        "print(f\"üìä Inst√¢ncias por segundo (treinamento): {train_ips:.2f}\")\n",
        "print(f\"üìä Inst√¢ncias por segundo (predi√ß√£o): {pred_ips:.2f}\")\n",
        "\n",
        "daily_predictions = 24 * 60 * 60 * pred_ips\n",
        "print(f\"\\nüìà THROUGHPUT PARA CEN√ÅRIOS REAIS:\")\n",
        "print(f\"Predi√ß√µes por segundo: {pred_ips:.0f}\")\n",
        "print(f\"Predi√ß√µes por minuto: {pred_ips * 60:.0f}\")\n",
        "print(f\"Predi√ß√µes por hora: {pred_ips * 3600:.0f}\")\n",
        "print(f\"Predi√ß√µes por dia: {daily_predictions:.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgb_features"
      },
      "outputs": [],
      "source": [
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': xgb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"IMPORT√ÇNCIA DAS FEATURES - XGBOOST\")\n",
        "print(\"=\"*50)\n",
        "print(feature_importance)\n",
        "\n",
        "# Visualiza√ß√£o da import√¢ncia das features\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Import√¢ncia das Features - XGBoost')\n",
        "plt.xlabel('Import√¢ncia')\n",
        "plt.ylabel('Features')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
